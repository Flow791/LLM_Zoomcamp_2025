#%%
import requests 
from elasticsearch import Elasticsearch
from tqdm import tqdm
import tiktoken

#%%
import os
from mistralai import Mistral
from dotenv import load_dotenv

load_dotenv()
mistral_key = os.getenv("MISTRAL_API_KEY")

model = "mistral-large-latest"
client = Mistral(api_key=mistral_key)

# %%
def elastic_search(query, size=3):
    search_query = {
        "size": size,
        "query": {
            "bool": {
                "must": {
                    "multi_match": {
                        "query": query,
                        "fields": ["question^4", "text"],
                        "type": "best_fields"
                    }
                },
                "filter": {
                    "term": {
                        "course": "machine-learning-zoomcamp"
                    }
                }
            }
        }
    }

    response = es_client.search(index=index_name, body=search_query)

    result_docs = []
    for hit in response['hits']['hits']:
        result_docs.append(hit)
        
    return result_docs

def build_prompt(query, search_results):
    prompt_template = """
        You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.
        Use only the facts from the CONTEXT when answering the QUESTION.

        QUESTION: {question}

        CONTEXT:
        {context}
        """.strip()

    context = ''

    for doc in search_results:
        doc_source = doc['_source']
        context = context + f"""
        Q: {doc_source["question"]}
        A: {doc_source["text"]}
        """.strip() + "\n\n"
        
    prompt = prompt_template.format(question=query, context=context)
    return prompt

def llm(prompt):
    chat_response = client.chat.complete(
        model=model,
        messages = [
            {
                "role": "user",
                "content": prompt,
            },
        ]
    )

    return chat_response.choices[0].message.content

def rag(query):
    search_results = elastic_search(query, 3)
    prompt = build_prompt(query, search_results)
    print(f'Prompt length: {len(prompt)}')
    answer = llm(prompt)
    
    return answer

#%%
docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'
docs_response = requests.get(docs_url)
documents_raw = docs_response.json()

documents = []

#%%
for course in documents_raw:
    course_name = course['course']

    for doc in course['documents']:
        doc['course'] = course_name
        documents.append(doc)

#%%    
documents[:5] 


# %%
es_client = Elasticsearch('http://localhost:9200')

index_settings = {
    "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0
    },
    "mappings": {
        "properties": {
            "text": {"type": "text"},
            "section": {"type": "text"},
            "question": {"type": "text"},
            "course": {"type": "keyword"} 
        }
    }
}

index_name = 'course-questions'

es_client.indices.create(index=index_name, body=index_settings)
# %%
for doc in tqdm(documents):
    es_client.index(index=index_name, body=doc)
    
# %%
##Question 2
elastic_search('How do execute a command on a Kubernetes pod?')[0]['_score']

# %%
##Question 3
elastic_search('How do copy a file to a Docker container?')[2]['_source']['question']
# %%
##Question 4
answer = rag('How do copy a file to a Docker container?')
print(answer)

# %%
##Question 5
query = 'How do copy a file to a Docker container?'
search_results = elastic_search(query, 3)
prompt = build_prompt(query, search_results)
encoding = tiktoken.encoding_for_model('gpt-4o')

len(encoding.encode(prompt))
# %%
